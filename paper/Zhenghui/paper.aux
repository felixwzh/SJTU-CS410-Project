\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{hosmer2013applied}
\citation{cortes1995support}
\citation{cristianini1999introduction}
\citation{liu2005one}
\citation{knerr1990single}
\citation{madzarov2009multi}
\citation{breiman2001random}
\citation{zhou2012ensemble}
\citation{safavian1991survey}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Models}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Logistic Regression}{1}{subsection.2.1}}
\newlabel{lr_1}{{1}{1}{Logistic Regression}{equation.2.1}{}}
\newlabel{lr_2}{{2}{1}{Logistic Regression}{equation.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Support Vector Machine}{1}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Random Forest}{1}{subsection.2.3}}
\citation{breiman1984classification}
\citation{breiman2001random}
\citation{breiman2001random}
\citation{zhou2017deep}
\citation{he2016deep}
\citation{hochreiter1997long}
\citation{zhou2017deep}
\citation{dunteman1989principal}
\citation{ng2011sparse}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An illustration for random forest.\relax }}{2}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rand-forest}{{1}{2}{An illustration for random forest.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Deep Forest}{2}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Illustration of feature re-representation using multi-grained sacnning. Suppose there are three classes, raw features are 400-dim, and sliding window is 100-dim.\relax }}{2}{figure.caption.4}}
\newlabel{fig:multi-grained-scanning}{{2}{2}{Illustration of feature re-representation using multi-grained sacnning. Suppose there are three classes, raw features are 400-dim, and sliding window is 100-dim.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Principal Components Analysis}{2}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Autoencoder}{2}{subsection.2.6}}
\citation{Deeplearning}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The overall procedure of deep forest. Suppose there are three classes to predict, raw features are 400-dim, and three sizes of sliding windows are used.\relax }}{3}{figure.caption.5}}
\newlabel{fig:deep-forest}{{3}{3}{The overall procedure of deep forest. Suppose there are three classes to predict, raw features are 400-dim, and three sizes of sliding windows are used.\relax }{figure.caption.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Principal Components Analysis\relax }}{3}{algorithm.1}}
\newlabel{alg:PCA}{{1}{3}{Principal Components Analysis\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Deep Neural Network}{3}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}network structure}{3}{subsubsection.2.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces structure of autoencoder\relax }}{3}{figure.caption.6}}
\newlabel{auto_1}{{4}{3}{structure of autoencoder\relax }{figure.caption.6}{}}
\citation{Dropout}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces a.network i; b, network ii\relax }}{4}{figure.caption.7}}
\newlabel{nn_1}{{5}{4}{a.network \romannumeral 1; b, network \romannumeral 2\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.2}Regularization}{4}{subsubsection.2.7.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.3}Pre-train}{4}{subsubsection.2.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces a.network i; b, network ii; c, network iii; d, network iv(From left to right and top to down). \relax }}{4}{figure.caption.8}}
\newlabel{pretrain_1}{{6}{4}{a.network \romannumeral 1; b, network \romannumeral 2; c, network \romannumeral 3; d, network \romannumeral 4 (From left to right and top to down). \relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Statistics of the 4 labels used in our experiments. \relax }}{4}{table.caption.11}}
\newlabel{tab:label}{{1}{4}{Statistics of the 4 labels used in our experiments. \relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Label Selection}{4}{subsection.3.1}}
\citation{chollet2015keras}
\citation{zhou2017deep}
\citation{scikit-learn}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Statistics of label \textit  {DiseaseState}\relax }}{5}{figure.caption.9}}
\newlabel{fig:Stat_DiseaseState}{{7}{5}{Statistics of label \textit {DiseaseState}\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Statistics of label \textit  {BioSourceType}\relax }}{5}{figure.caption.10}}
\newlabel{fig:Stat_BioSourceType}{{8}{5}{Statistics of label \textit {BioSourceType}\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experiment Details}{5}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Cross Validation}{5}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Problem formulation}{5}{subsubsection.3.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Evaluation Metric}{5}{subsubsection.3.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces a.Material-2 Distribution; b, Sex-2 Distribution2; c, Disease-16 Distribution; d,Bio-7 Distribution (From top to down). \relax }}{5}{figure.caption.12}}
\newlabel{distribution_1}{{9}{5}{a.Material-2 Distribution; b, Sex-2 Distribution2; c, Disease-16 Distribution; d,Bio-7 Distribution (From top to down). \relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Reserved Variance (\%) of different reduced dimension. \relax }}{5}{table.caption.13}}
\newlabel{tab:PCA}{{2}{5}{Reserved Variance (\%) of different reduced dimension. \relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Implementation}{5}{subsubsection.3.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Dimensionality Reduction}{5}{subsection.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Best results and parameter settings for Logistic Regression. \relax }}{6}{table.caption.16}}
\newlabel{lr_result2}{{3}{6}{Best results and parameter settings for Logistic Regression. \relax }{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The performance of SVM in 4 tasks with different data reduced dimensions.\relax }}{6}{figure.caption.14}}
\newlabel{fig:PCA_Dimension}{{10}{6}{The performance of SVM in 4 tasks with different data reduced dimensions.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results \& Analysis}{6}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Logistic Regression}{6}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}SVM}{6}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The performance of LR in 4 tasks with different regularization strength.\relax }}{6}{figure.caption.15}}
\newlabel{lr_result1}{{11}{6}{The performance of LR in 4 tasks with different regularization strength.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Influence of $\gamma $ in polynomial kernel.\relax }}{6}{figure.caption.17}}
\newlabel{fig:gamma_poly}{{12}{6}{Influence of $\gamma $ in polynomial kernel.\relax }{figure.caption.17}{}}
\citation{zhou2017deep}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Influence of $\gamma $ in RBF kernel.\relax }}{7}{figure.caption.18}}
\newlabel{fig:gamma_rbf}{{13}{7}{Influence of $\gamma $ in RBF kernel.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Influence of $\gamma $ in sigmoid kernel.\relax }}{7}{figure.caption.19}}
\newlabel{fig:gamma_sigmoid}{{14}{7}{Influence of $\gamma $ in sigmoid kernel.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Influence of $C$ in polynomial kernels\relax }}{7}{figure.caption.20}}
\newlabel{fig:C_poly}{{15}{7}{Influence of $C$ in polynomial kernels\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Random Forest}{7}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Influence of $C$ in RBF kernels\relax }}{7}{figure.caption.21}}
\newlabel{fig:C_rbf}{{16}{7}{Influence of $C$ in RBF kernels\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Influence of $C$ in sigmoid kernels\relax }}{7}{figure.caption.22}}
\newlabel{fig:C_sigmoid}{{17}{7}{Influence of $C$ in sigmoid kernels\relax }{figure.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Best parameter settings for SVM model. \relax }}{7}{table.caption.23}}
\newlabel{tab:SVM}{{4}{7}{Best parameter settings for SVM model. \relax }{table.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Best parameter settings for random forest model. \relax }}{8}{table.caption.24}}
\newlabel{tab:RF}{{5}{8}{Best parameter settings for random forest model. \relax }{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Influence of \textit  {min\_samples\_leaf} in random forest.\relax }}{8}{figure.caption.25}}
\newlabel{fig:min_samples_leaf}{{18}{8}{Influence of \textit {min\_samples\_leaf} in random forest.\relax }{figure.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Best parameter settings for random forest model. \relax }}{8}{table.caption.26}}
\newlabel{tab:DeepForest}{{6}{8}{Best parameter settings for random forest model. \relax }{table.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Deep Forets}{8}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Deep Neural Network}{8}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1} NN on PCA-processed data}{8}{subsubsection.4.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Best results and parameter settings for NN model on PCA data. \relax }}{8}{table.caption.27}}
\newlabel{nnpca_result}{{7}{8}{Best results and parameter settings for NN model on PCA data. \relax }{table.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces a.accuracy in Bio task; b, accuracy in Sex task; c, loss in Bio task; d, loss in Sex task (From left to right and top to down). \relax }}{8}{figure.caption.28}}
\newlabel{lr_result}{{19}{8}{a.accuracy in Bio task; b, accuracy in Sex task; c, loss in Bio task; d, loss in Sex task (From left to right and top to down). \relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2} NN on raw data}{8}{subsubsection.4.5.2}}
\bibstyle{ACM-Reference-Format}
\bibdata{bibliography}
\bibcite{breiman2001random}{{1}{2001}{{Breiman}}{{Breiman}}}
\bibcite{breiman1984classification}{{2}{1984}{{Breiman et~al\unhbox \voidb@x \hbox {.}}}{{Breiman, Friedman, Stone, and Olshen}}}
\bibcite{chollet2015keras}{{3}{2015}{{Chollet et~al\unhbox \voidb@x \hbox {.}}}{{Chollet et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{cortes1995support}{{4}{1995}{{Cortes and Vapnik}}{{Cortes and Vapnik}}}
\bibcite{cristianini1999introduction}{{5}{1999}{{{Cristianini} and {Shawe-Taylor}}}{{{Cristianini} and {Shawe-Taylor}}}}
\bibcite{dunteman1989principal}{{6}{1989}{{Dunteman}}{{Dunteman}}}
\bibcite{he2016deep}{{7}{2016}{{He et~al\unhbox \voidb@x \hbox {.}}}{{He, Zhang, Ren, and Sun}}}
\bibcite{hochreiter1997long}{{8}{1997}{{Hochreiter and Schmidhuber}}{{Hochreiter and Schmidhuber}}}
\bibcite{hosmer2013applied}{{9}{2013}{{Hosmer~Jr et~al\unhbox \voidb@x \hbox {.}}}{{Hosmer~Jr, Lemeshow, and Sturdivant}}}
\bibcite{knerr1990single}{{10}{1990}{{Knerr et~al\unhbox \voidb@x \hbox {.}}}{{Knerr, Personnaz, and Dreyfus}}}
\bibcite{liu2005one}{{11}{2005}{{Liu and Zheng}}{{Liu and Zheng}}}
\bibcite{madzarov2009multi}{{12}{2009}{{Madzarov et~al\unhbox \voidb@x \hbox {.}}}{{Madzarov, Gjorgjevikj, and Chorbev}}}
\bibcite{Dropout}{{13}{2014}{{N.~Srivastava and Salakhutdinov}}{{N.~Srivastava and Salakhutdinov}}}
\bibcite{ng2011sparse}{{14}{2011}{{Ng}}{{Ng}}}
\bibcite{scikit-learn}{{15}{2011}{{Pedregosa et~al\unhbox \voidb@x \hbox {.}}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{safavian1991survey}{{16}{1991}{{Safavian and Landgrebe}}{{Safavian and Landgrebe}}}
\bibcite{Deeplearning}{{17}{2015}{{Y.~LeCun and Hinton}}{{Y.~LeCun and Hinton}}}
\bibcite{zhou2012ensemble}{{18}{2012}{{Zhou}}{{Zhou}}}
\bibcite{zhou2017deep}{{19}{2017}{{Zhou and Feng}}{{Zhou and Feng}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.62497pt}
\newlabel{tocindent2}{11.81937pt}
\newlabel{tocindent3}{22.09708pt}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Best results and parameter settings for NN model on raw data. \relax }}{9}{table.caption.29}}
\newlabel{nnraw_result}{{8}{9}{Best results and parameter settings for NN model on raw data. \relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {section}{Acknowledgments}{9}{section*.31}}
\@writefile{toc}{\contentsline {section}{References}{9}{section*.33}}
\newlabel{TotPages}{{9}{9}{}{page.9}{}}
